
[root@node3 hadoop]# cat /opt/hadoop-2.6.5/logs/hadoop-root-datanode-node3.log
2021-06-12 01:33:12,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:33:12,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:33:15,615 FATAL org.apache.hadoop.conf.Configuration: bad conf file: top-level element not <configuration>
2021-06-12 01:33:15,615 WARN org.apache.hadoop.conf.Configuration: bad conf file: element not <property>
2021-06-12 01:33:15,615 WARN org.apache.hadoop.conf.Configuration: bad conf file: element not <property>
2021-06-12 01:33:15,824 FATAL org.apache.hadoop.conf.Configuration: error parsing conf hdfs-site.xml
org.xml.sax.SAXParseException; systemId: file:/opt/hadoop-2.6.5/etc/hadoop/hdfs-site.xml; lineNumber: 23; columnNumber: 2; The markup in the document following the root element must be well-formed.
        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
        at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2432)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2420)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2491)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2444)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2361)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1099)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1071)
        at org.apache.hadoop.conf.Configuration.setBoolean(Configuration.java:1409)
        at org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:319)
        at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:485)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:170)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:153)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2207)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:33:15,860 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.lang.RuntimeException: org.xml.sax.SAXParseException; systemId: file:/opt/hadoop-2.6.5/etc/hadoop/hdfs-site.xml; lineNumber: 23; columnNumber: 2; The markup in the document following the root element must be well-formed.
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2597)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2444)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2361)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1099)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1071)
        at org.apache.hadoop.conf.Configuration.setBoolean(Configuration.java:1409)
        at org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:319)
        at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:485)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:170)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:153)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2207)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
Caused by: org.xml.sax.SAXParseException; systemId: file:/opt/hadoop-2.6.5/etc/hadoop/hdfs-site.xml; lineNumber: 23; columnNumber: 2; The markup in the document following the root element must be well-formed.
        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
        at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2432)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2420)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2491)
        ... 13 more
2021-06-12 01:33:15,887 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:33:16,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:37:54,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:37:54,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:38:01,433 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 01:38:04,974 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 01:38:06,608 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 01:38:06,608 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 01:38:06,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 01:38:06,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 01:38:07,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 01:38:07,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 01:38:07,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 01:38:09,659 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 01:38:09,712 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 01:38:09,881 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 01:38:10,018 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 01:38:10,019 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 01:38:10,019 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 01:38:10,199 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 01:38:10,215 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 01:38:10,215 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 01:38:13,063 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:38:16,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 01:38:16,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 01:38:17,268 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 01:38:17,543 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 01:38:17,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 01:38:17,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 01:38:18,320 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:38:18,324 WARN org.apache.hadoop.http.HttpServer2: HttpServer Acceptor: isRunning is false. Rechecking.
2021-06-12 01:38:18,359 WARN org.apache.hadoop.http.HttpServer2: HttpServer Acceptor: isRunning is false
2021-06-12 01:38:19,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 01:38:19,148 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 01:38:19,166 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 01:38:19,171 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 01:38:19,172 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 01:38:19,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 01:38:19,179 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:38:19,262 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:38:19,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:40:12,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:40:12,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:40:20,538 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 01:40:24,682 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 01:40:26,416 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 01:40:26,417 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 01:40:26,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 01:40:26,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 01:40:27,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 01:40:27,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 01:40:27,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 01:40:28,490 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 01:40:28,651 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 01:40:28,768 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 01:40:28,900 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 01:40:28,901 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 01:40:28,901 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 01:40:29,119 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 01:40:29,135 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 01:40:29,135 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 01:40:31,566 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:40:34,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 01:40:34,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 01:40:35,490 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 01:40:35,947 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 01:40:36,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 01:40:36,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 01:40:36,804 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:40:36,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 01:40:36,951 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 01:40:36,978 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 01:40:36,980 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 01:40:36,982 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 01:40:36,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 01:40:37,001 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:40:37,035 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:40:37,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:51:29,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:51:30,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:51:35,769 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 01:51:38,777 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 01:51:39,606 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 01:51:39,606 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 01:51:39,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 01:51:39,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 01:51:39,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 01:51:39,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 01:51:39,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 01:51:40,412 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 01:51:40,444 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 01:51:40,515 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 01:51:40,538 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 01:51:40,538 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 01:51:40,538 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 01:51:40,653 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 01:51:40,662 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 01:51:40,663 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 01:51:41,760 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:51:43,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 01:51:43,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 01:51:44,205 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 01:51:44,373 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 01:51:44,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 01:51:44,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 01:51:44,840 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:51:44,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 01:51:44,953 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 01:51:44,956 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 01:51:44,959 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 01:51:44,959 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 01:51:44,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 01:51:44,964 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:51:44,985 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:51:45,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:52:10,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:52:10,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:52:12,947 FATAL org.apache.hadoop.conf.Configuration: error parsing conf core-site.xml
org.xml.sax.SAXParseException; systemId: file:/opt/hadoop-2.6.5/etc/hadoop/core-site.xml; lineNumber: 23; columnNumber: 7; The element type "progerty" must be terminated by the matching end-tag "</progerty>".
        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
        at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2432)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2420)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2491)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2444)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2361)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1099)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1071)
        at org.apache.hadoop.conf.Configuration.setBoolean(Configuration.java:1409)
        at org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:319)
        at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:485)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:170)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:153)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2207)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:52:12,977 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.lang.RuntimeException: org.xml.sax.SAXParseException; systemId: file:/opt/hadoop-2.6.5/etc/hadoop/core-site.xml; lineNumber: 23; columnNumber: 7; The element type "progerty" must be terminated by the matching end-tag "</progerty>".
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2597)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2444)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2361)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1099)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1071)
        at org.apache.hadoop.conf.Configuration.setBoolean(Configuration.java:1409)
        at org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:319)
        at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:485)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:170)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:153)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2207)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
Caused by: org.xml.sax.SAXParseException; systemId: file:/opt/hadoop-2.6.5/etc/hadoop/core-site.xml; lineNumber: 23; columnNumber: 7; The element type "progerty" must be terminated by the matching end-tag "</progerty>".
        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
        at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2432)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2420)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2491)
        ... 13 more
2021-06-12 01:52:13,001 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:52:13,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:53:20,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:53:20,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:53:29,174 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 01:53:33,959 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 01:53:36,058 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 01:53:36,059 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 01:53:36,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 01:53:36,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 01:53:36,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 01:53:36,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 01:53:36,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 01:53:37,952 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 01:53:38,142 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 01:53:38,263 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 01:53:38,315 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 01:53:38,316 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 01:53:38,318 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 01:53:38,566 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 01:53:38,581 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 01:53:38,582 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 01:53:41,394 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:53:44,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 01:53:44,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 01:53:45,417 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 01:53:45,817 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 01:53:46,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 01:53:46,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 01:53:46,583 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:53:46,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 01:53:46,604 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 01:53:46,631 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 01:53:46,633 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 01:53:46,633 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 01:53:46,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 01:53:46,647 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:53:46,684 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:53:46,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:54:32,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:54:32,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:54:38,895 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 01:54:42,604 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 01:54:44,094 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 01:54:44,095 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 01:54:44,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 01:54:44,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 01:54:44,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 01:54:44,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 01:54:44,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 01:54:45,404 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 01:54:45,451 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 01:54:45,555 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 01:54:45,604 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 01:54:45,605 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 01:54:45,605 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 01:54:45,739 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 01:54:45,750 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 01:54:45,750 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 01:54:47,457 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:54:49,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 01:54:49,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 01:54:50,526 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 01:54:50,892 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 01:54:51,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 01:54:51,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 01:54:51,638 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:54:51,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 01:54:51,753 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 01:54:51,771 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 01:54:51,775 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 01:54:51,776 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 01:54:51,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 01:54:51,784 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:54:51,824 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:54:51,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:58:24,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:58:24,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:58:30,036 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 01:58:33,465 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 01:58:35,157 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 01:58:35,157 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 01:58:35,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 01:58:35,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 01:58:35,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 01:58:35,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 01:58:35,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 01:58:36,978 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 01:58:37,017 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 01:58:37,107 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 01:58:37,174 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 01:58:37,176 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 01:58:37,176 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 01:58:37,326 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 01:58:37,340 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 01:58:37,340 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 01:58:39,282 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:58:42,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 01:58:42,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 01:58:42,629 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 01:58:42,856 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 01:58:43,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 01:58:43,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 01:58:43,402 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:58:43,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 01:58:43,513 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 01:58:43,528 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 01:58:43,530 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 01:58:43,531 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 01:58:43,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 01:58:43,536 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:58:43,567 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:58:43,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 01:59:17,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 01:59:17,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 01:59:23,549 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 01:59:26,602 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 01:59:27,975 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 01:59:27,976 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 01:59:28,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 01:59:28,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 01:59:28,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 01:59:28,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 01:59:28,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 01:59:29,170 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 01:59:29,206 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 01:59:29,284 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 01:59:29,302 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 01:59:29,303 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 01:59:29,303 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 01:59:29,390 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 01:59:29,396 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 01:59:29,397 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 01:59:30,739 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:59:32,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 01:59:32,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 01:59:33,390 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 01:59:33,564 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 01:59:33,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 01:59:33,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 01:59:34,041 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 01:59:34,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 01:59:34,150 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 01:59:34,157 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 01:59:34,161 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 01:59:34,162 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 01:59:34,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 01:59:34,169 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 01:59:34,202 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 01:59:34,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 02:04:42,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 02:04:43,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 02:04:50,557 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 02:04:53,784 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 02:04:55,509 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 02:04:55,511 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 02:04:55,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 02:04:55,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 02:04:55,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 02:04:56,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 02:04:56,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 02:04:56,784 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 02:04:56,818 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 02:04:56,936 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 02:04:56,983 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 02:04:56,983 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 02:04:56,984 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 02:04:57,150 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 02:04:57,182 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 02:04:57,183 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 02:04:59,182 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 02:05:01,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 02:05:01,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 02:05:01,868 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 02:05:02,052 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 02:05:02,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 02:05:02,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 02:05:02,945 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 02:05:07,170 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5280ms
GC pool 'Copy' had collection(s): count=2 time=12ms
2021-06-12 02:05:07,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 02:05:07,171 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 02:05:07,175 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 02:05:07,177 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 02:05:07,178 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 02:05:07,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 02:05:07,181 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 02:05:07,199 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 02:05:07,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 02:06:41,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 02:06:41,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 02:06:47,645 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 02:06:51,457 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 02:06:53,120 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 02:06:53,121 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 02:06:53,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 02:06:53,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 02:06:53,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 02:06:53,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 02:06:53,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 02:06:55,543 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 02:06:55,579 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 02:06:55,679 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 02:06:55,926 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 02:06:55,926 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 02:06:55,926 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 02:06:56,102 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 02:06:56,217 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 02:06:56,217 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 02:06:58,572 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 02:07:01,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 02:07:01,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 02:07:02,004 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 02:07:02,222 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 02:07:02,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 02:07:03,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 02:07:03,724 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 02:07:03,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2021-06-12 02:07:03,764 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2021-06-12 02:07:03,784 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2021-06-12 02:07:03,806 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2021-06-12 02:07:03,807 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2021-06-12 02:07:03,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-06-12 02:07:03,832 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
        at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:875)
        at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1106)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:418)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2332)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2219)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
2021-06-12 02:07:03,930 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-06-12 02:07:04,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 02:09:58,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 02:09:59,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 02:10:04,491 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 02:10:07,836 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 02:10:09,268 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 02:10:09,269 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 02:10:09,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 02:10:09,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 02:10:09,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 02:10:09,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 02:10:09,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 02:10:10,895 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 02:10:10,944 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 02:10:11,061 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 02:10:11,101 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 02:10:11,101 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 02:10:11,101 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 02:10:11,309 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 02:10:11,406 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 02:10:11,406 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 02:10:13,722 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 02:10:16,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 02:10:16,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 02:10:17,052 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 02:10:17,422 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 02:10:18,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 02:10:18,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-12 02:10:18,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-12 02:10:18,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:9000 starting to offer service
2021-06-12 02:10:18,813 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-12 02:10:18,830 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-12 02:10:21,339 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/bjsxt/hadoop/full/dfs/data/in_use.lock acquired by nodename 3010@node3
2021-06-12 02:10:21,350 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /var/bjsxt/hadoop/full/dfs/data is not formatted for BP-219893226-192.168.98.61-1623434386765
2021-06-12 02:10:21,351 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-06-12 02:10:21,715 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-219893226-192.168.98.61-1623434386765
2021-06-12 02:10:21,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /var/bjsxt/hadoop/full/dfs/data/current/BP-219893226-192.168.98.61-1623434386765
2021-06-12 02:10:21,720 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /var/bjsxt/hadoop/full/dfs/data/current/BP-219893226-192.168.98.61-1623434386765 is not formatted for BP-219893226-192.168.98.61-1623434386765
2021-06-12 02:10:21,721 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-06-12 02:10:21,721 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-219893226-192.168.98.61-1623434386765 directory /var/bjsxt/hadoop/full/dfs/data/current/BP-219893226-192.168.98.61-1623434386765/current
2021-06-12 02:10:21,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-06-12 02:10:21,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=365511146;bpid=BP-219893226-192.168.98.61-1623434386765;lv=-56;nsInfo=lv=-60;cid=CID-026fafac-4538-41aa-b7ad-951009fb8873;nsid=365511146;c=0;bpid=BP-219893226-192.168.98.61-1623434386765;dnuuid=null
2021-06-12 02:10:21,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 9922870b-d576-4e88-a628-91fbd17386bd
2021-06-12 02:10:22,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /var/bjsxt/hadoop/full/dfs/data/current
2021-06-12 02:10:22,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /var/bjsxt/hadoop/full/dfs/data/current, StorageType: DISK
2021-06-12 02:10:22,129 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-12 02:10:22,129 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-219893226-192.168.98.61-1623434386765
2021-06-12 02:10:22,134 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-219893226-192.168.98.61-1623434386765 on volume /var/bjsxt/hadoop/full/dfs/data/current...
2021-06-12 02:10:22,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-219893226-192.168.98.61-1623434386765 on /var/bjsxt/hadoop/full/dfs/data/current: 176ms
2021-06-12 02:10:22,315 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-219893226-192.168.98.61-1623434386765: 185ms
2021-06-12 02:10:22,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-219893226-192.168.98.61-1623434386765 on volume /var/bjsxt/hadoop/full/dfs/data/current...
2021-06-12 02:10:22,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-219893226-192.168.98.61-1623434386765 on volume /var/bjsxt/hadoop/full/dfs/data/current: 0ms
2021-06-12 02:10:22,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2021-06-12 02:10:22,345 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1623454161345 with interval 21600000
2021-06-12 02:10:22,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-219893226-192.168.98.61-1623434386765 (Datanode Uuid null) service to node1/192.168.98.61:9000 beginning handshake with NN
2021-06-12 02:10:22,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-219893226-192.168.98.61-1623434386765 (Datanode Uuid null) service to node1/192.168.98.61:9000 successfully registered with NN
2021-06-12 02:10:22,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/192.168.98.61:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-12 02:10:23,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-219893226-192.168.98.61-1623434386765 (Datanode Uuid 9922870b-d576-4e88-a628-91fbd17386bd) service to node1/192.168.98.61:9000 trying to claim ACTIVE state with txid=2
2021-06-12 02:10:23,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-219893226-192.168.98.61-1623434386765 (Datanode Uuid 9922870b-d576-4e88-a628-91fbd17386bd) service to node1/192.168.98.61:9000
2021-06-12 02:10:23,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe9e1ba73e0f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 160 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-12 02:10:23,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-219893226-192.168.98.61-1623434386765
2021-06-12 02:10:23,240 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-06-12 02:10:23,241 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-12 02:10:23,251 INFO org.apache.hadoop.util.GSet: 0.5% max memory 966.7 MB = 4.8 MB
2021-06-12 02:10:23,252 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-06-12 02:10:23,264 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-219893226-192.168.98.61-1623434386765
2021-06-12 02:10:23,298 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-219893226-192.168.98.61-1623434386765 to blockPoolScannerMap, new size=1
2021-06-12 04:30:59,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x164a52f36965,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-12 04:30:59,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-219893226-192.168.98.61-1623434386765
2021-06-12 05:46:28,990 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3113ms
No GCs detected
2021-06-12 07:29:21,387 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-219893226-192.168.98.61-1623434386765 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-06-12 07:31:00,628 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-12 07:31:00,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 07:33:32,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 07:33:32,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 07:33:37,482 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 07:33:40,919 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 07:33:42,802 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 07:33:42,802 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 07:33:42,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 07:33:42,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 07:33:43,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 07:33:43,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 07:33:43,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 07:33:45,194 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 07:33:45,340 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 07:33:45,554 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 07:33:45,621 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 07:33:45,622 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 07:33:45,622 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 07:33:45,964 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 07:33:46,033 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 07:33:46,034 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 07:33:48,724 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 07:33:52,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 07:33:52,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 07:33:53,055 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 07:33:53,639 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 07:33:54,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 07:33:54,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1,ns2
2021-06-12 07:33:54,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1,ns2
2021-06-12 07:33:54,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020 starting to offer service
2021-06-12 07:33:54,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020 starting to offer service
2021-06-12 07:33:54,744 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-12 07:33:54,776 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-12 07:33:57,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:33:57,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:33:58,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:33:58,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:33:59,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:33:59,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:00,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:00,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:01,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:01,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:02,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:02,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:03,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:03,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:04,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:04,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:05,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:05,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:06,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:06,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:34:06,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:06,293 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:34:12,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:12,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:13,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:13,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:14,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:14,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:15,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:15,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:16,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:16,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:17,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:17,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:18,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:18,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:19,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:19,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:20,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:20,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:21,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:21,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:21,347 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:34:21,347 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:34:27,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:27,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:28,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:28,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:29,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:29,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:30,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:30,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:31,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:31,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:32,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:32,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:33,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:33,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:34,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:34,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:35,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:35,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:36,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:36,422 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:34:36,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:36,424 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:34:42,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:42,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:43,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:43,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:44,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:44,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:45,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:45,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:46,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:46,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:47,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:47,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:48,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:48,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:49,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:49,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:50,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:50,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:51,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:51,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:51,466 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:34:51,467 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:34:57,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:57,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:58,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:58,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:59,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:34:59,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:00,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:00,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:01,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:01,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:02,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:02,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:03,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:03,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:04,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:04,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:05,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:05,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:06,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:06,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:06,536 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:35:06,538 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:35:12,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:12,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:13,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:13,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:14,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:14,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:15,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:15,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:16,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:16,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:17,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:17,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:18,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:18,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:19,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:19,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:20,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:20,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:21,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:21,629 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:35:21,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:21,635 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:35:27,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:27,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:28,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:28,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:29,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:29,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:30,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:30,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:31,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:31,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:32,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:32,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:33,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:33,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:34,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:34,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:35,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:35,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:36,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:36,727 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:35:36,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:36,734 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:35:42,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:42,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:43,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:43,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:44,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:44,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:45,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:45,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:46,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:46,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:47,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:47,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:48,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:48,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:49,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:49,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:50,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:50,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:51,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:51,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:51,779 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:35:51,784 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:35:57,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:57,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:58,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:58,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:59,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:35:59,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:00,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:00,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:01,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:01,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:02,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:02,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:03,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:03,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:04,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:04,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:05,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:05,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:06,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:06,853 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:36:06,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:06,858 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:36:12,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:12,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:13,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:13,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:14,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:14,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:15,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:15,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:16,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:16,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:17,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:17,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:18,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:18,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:19,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:19,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:20,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:20,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:21,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:21,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:21,979 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:36:21,982 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:36:27,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:27,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:28,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:28,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:29,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:30,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:31,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:31,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:32,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:32,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:33,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:33,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:34,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:34,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:35,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:35,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:36,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:36,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:37,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:37,060 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:36:37,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:37,065 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:36:43,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:43,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:44,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:44,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:45,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:45,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:46,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:46,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:47,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:47,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:48,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:48,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:49,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:49,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:50,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:50,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:51,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:51,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:52,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:52,102 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:36:52,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:52,135 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:36:58,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:58,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:59,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:36:59,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:00,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:00,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:01,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:01,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:02,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:02,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:03,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:03,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:04,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:04,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:05,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:05,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:06,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:06,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:07,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:07,168 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:37:07,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:07,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:37:13,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:13,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:14,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:14,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:15,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:15,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:16,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:16,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:17,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:17,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:18,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:18,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:19,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:19,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:20,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:20,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:21,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:21,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:22,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:22,206 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:37:22,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:22,264 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:37:28,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:28,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:29,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:29,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:30,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:30,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:31,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:31,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:32,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:32,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:33,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:33,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:34,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:34,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:35,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:35,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:36,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:36,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:37,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:37,247 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/192.168.98.61:8020
2021-06-12 07:37:37,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:37,328 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node2/192.168.98.62:8020
2021-06-12 07:37:43,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:43,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:44,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:44,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node2/192.168.98.62:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:45,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:46,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:37:48,131 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/bjsxt/hadoop/federation/dfs/data/in_use.lock acquired by nodename 3481@node3
2021-06-12 07:37:48,144 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /var/bjsxt/hadoop/federation/dfs/data is not formatted for BP-626842139-192.168.98.61-1623454743066
2021-06-12 07:37:48,144 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-06-12 07:37:48,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-626842139-192.168.98.61-1623454743066
2021-06-12 07:37:48,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /var/bjsxt/hadoop/federation/dfs/data/current/BP-626842139-192.168.98.61-1623454743066
2021-06-12 07:37:48,684 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /var/bjsxt/hadoop/federation/dfs/data/current/BP-626842139-192.168.98.61-1623454743066 is not formatted for BP-626842139-192.168.98.61-1623454743066
2021-06-12 07:37:48,684 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-06-12 07:37:48,684 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-626842139-192.168.98.61-1623454743066 directory /var/bjsxt/hadoop/federation/dfs/data/current/BP-626842139-192.168.98.61-1623454743066/current
2021-06-12 07:37:48,715 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-06-12 07:37:48,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=607953156;bpid=BP-626842139-192.168.98.61-1623454743066;lv=-56;nsInfo=lv=-60;cid=CID-78377eff-58d6-470c-97b0-0397405d404c;nsid=607953156;c=0;bpid=BP-626842139-192.168.98.61-1623454743066;dnuuid=null
2021-06-12 07:37:48,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID b51a8b26-e28b-4611-bb69-d07414393230
2021-06-12 07:37:49,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /var/bjsxt/hadoop/federation/dfs/data/current
2021-06-12 07:37:49,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /var/bjsxt/hadoop/federation/dfs/data/current, StorageType: DISK
2021-06-12 07:37:49,267 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-12 07:37:49,268 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-626842139-192.168.98.61-1623454743066
2021-06-12 07:37:49,280 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020. Exiting.
java.io.IOException: Cluster IDs not matched: dn cid=CID-78377eff-58d6-470c-97b0-0397405d404c but ns cid=CID-6788a027-b046-4e08-8909-b990e7e331f5; bpid=BP-49446180-192.168.98.62-1623454597303
        at org.apache.hadoop.hdfs.server.datanode.DataNode.setClusterId(DataNode.java:604)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1301)
        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
        at java.lang.Thread.run(Thread.java:748)
2021-06-12 07:37:49,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020
2021-06-12 07:37:49,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-626842139-192.168.98.61-1623454743066 on volume /var/bjsxt/hadoop/federation/dfs/data/current...
2021-06-12 07:37:49,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-06-12 07:37:49,896 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-626842139-192.168.98.61-1623454743066 on /var/bjsxt/hadoop/federation/dfs/data/current: 513ms
2021-06-12 07:37:49,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-626842139-192.168.98.61-1623454743066: 622ms
2021-06-12 07:37:49,972 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-626842139-192.168.98.61-1623454743066 on volume /var/bjsxt/hadoop/federation/dfs/data/current...
2021-06-12 07:37:50,002 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-626842139-192.168.98.61-1623454743066 on volume /var/bjsxt/hadoop/federation/dfs/data/current: 30ms
2021-06-12 07:37:50,002 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 105ms
2021-06-12 07:37:50,081 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1623458870081 with interval 21600000
2021-06-12 07:37:50,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-626842139-192.168.98.61-1623454743066 (Datanode Uuid null) service to node1/192.168.98.61:8020 beginning handshake with NN
2021-06-12 07:37:50,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-626842139-192.168.98.61-1623454743066 (Datanode Uuid null) service to node1/192.168.98.61:8020 successfully registered with NN
2021-06-12 07:37:50,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/192.168.98.61:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-12 07:37:51,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-626842139-192.168.98.61-1623454743066 (Datanode Uuid b51a8b26-e28b-4611-bb69-d07414393230) service to node1/192.168.98.61:8020 trying to claim ACTIVE state with txid=1
2021-06-12 07:37:51,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-626842139-192.168.98.61-1623454743066 (Datanode Uuid b51a8b26-e28b-4611-bb69-d07414393230) service to node1/192.168.98.61:8020
2021-06-12 07:37:51,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x207cd4d5e274,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 527 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-12 07:37:51,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-626842139-192.168.98.61-1623454743066
2021-06-12 07:37:51,943 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-06-12 07:37:51,944 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-12 07:37:51,964 INFO org.apache.hadoop.util.GSet: 0.5% max memory 966.7 MB = 4.8 MB
2021-06-12 07:37:51,964 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-06-12 07:37:51,965 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-626842139-192.168.98.61-1623454743066
2021-06-12 07:37:52,026 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-626842139-192.168.98.61-1623454743066 to blockPoolScannerMap, new size=1
2021-06-12 07:38:27,047 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "node3/192.168.98.63"; destination host is: "node1":8020;
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
        at org.apache.hadoop.ipc.Client.call(Client.java:1474)
        at org.apache.hadoop.ipc.Client.call(Client.java:1401)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
        at com.sun.proxy.$Proxy12.sendHeartbeat(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:139)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:617)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:715)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:889)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
        at sun.nio.ch.IOUtil.read(IOUtil.java:197)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at java.io.FilterInputStream.read(FilterInputStream.java:133)
        at java.io.FilterInputStream.read(FilterInputStream.java:133)
        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1073)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:968)
2021-06-12 07:38:30,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:38:31,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.98.61:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-12 07:38:31,907 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-12 07:38:31,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 07:39:51,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 07:39:51,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 07:39:58,807 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 07:40:01,880 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 07:40:03,391 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 07:40:03,393 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 07:40:03,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 07:40:03,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 07:40:03,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 07:40:03,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 07:40:03,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 07:40:05,472 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 07:40:05,555 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 07:40:05,707 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 07:40:05,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 07:40:05,739 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 07:40:05,739 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 07:40:05,908 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 07:40:05,929 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 07:40:05,930 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 07:40:08,655 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 07:40:11,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 07:40:11,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 07:40:12,651 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 07:40:12,941 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 07:40:13,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 07:40:13,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1,ns2
2021-06-12 07:40:14,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1,ns2
2021-06-12 07:40:14,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020 starting to offer service
2021-06-12 07:40:14,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020 starting to offer service
2021-06-12 07:40:14,654 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-12 07:40:14,661 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-12 07:40:17,417 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020. Exiting.
java.io.IOException: Cluster IDs not matched: dn cid=CID-6788a027-b046-4e08-8909-b990e7e331f5 but ns cid=CID-78377eff-58d6-470c-97b0-0397405d404c; bpid=BP-626842139-192.168.98.61-1623454743066
        at org.apache.hadoop.hdfs.server.datanode.DataNode.setClusterId(DataNode.java:604)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1301)
        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
        at java.lang.Thread.run(Thread.java:748)
2021-06-12 07:40:17,493 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020
2021-06-12 07:40:17,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-06-12 07:40:17,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/bjsxt/hadoop/federation/dfs/data/in_use.lock acquired by nodename 3908@node3
2021-06-12 07:40:17,868 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /var/bjsxt/hadoop/federation/dfs/data: namenode clusterID = CID-6788a027-b046-4e08-8909-b990e7e331f5; datanode clusterID = CID-78377eff-58d6-470c-97b0-0397405d404c
2021-06-12 07:40:17,868 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020. Exiting.
java.io.IOException: All specified directories are failed to load.
        at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1342)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1308)
        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
        at java.lang.Thread.run(Thread.java:748)
2021-06-12 07:40:17,875 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020
2021-06-12 07:40:17,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-06-12 07:40:19,953 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-06-12 07:40:19,975 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-06-12 07:40:20,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 07:46:32,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/opt/hadoop-2.6.5/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.6.5/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.6.5/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 07:46:32,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 07:46:34,409 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 07:46:35,475 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 07:46:36,036 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 07:46:36,037 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 07:46:36,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 07:46:36,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 07:46:36,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 07:46:36,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 07:46:36,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 07:46:36,725 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 07:46:36,775 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 07:46:36,890 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 07:46:36,919 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 07:46:36,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 07:46:36,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 07:46:37,029 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 07:46:37,045 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 07:46:37,045 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 07:46:38,465 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 07:46:39,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 07:46:39,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 07:46:39,840 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 07:46:39,965 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 07:46:40,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 07:46:40,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1,ns2
2021-06-12 07:46:40,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1,ns2
2021-06-12 07:46:40,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020 starting to offer service
2021-06-12 07:46:40,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020 starting to offer service
2021-06-12 07:46:40,408 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-12 07:46:40,425 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-12 07:46:41,558 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020. Exiting.
java.io.IOException: Cluster IDs not matched: dn cid=CID-6788a027-b046-4e08-8909-b990e7e331f5 but ns cid=CID-78377eff-58d6-470c-97b0-0397405d404c; bpid=BP-626842139-192.168.98.61-1623454743066
        at org.apache.hadoop.hdfs.server.datanode.DataNode.setClusterId(DataNode.java:604)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1301)
        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
        at java.lang.Thread.run(Thread.java:748)
2021-06-12 07:46:41,600 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020
2021-06-12 07:46:41,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-06-12 07:46:41,668 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/bjsxt/hadoop/federation/dfs/data/in_use.lock acquired by nodename 4088@node3
2021-06-12 07:46:41,681 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /var/bjsxt/hadoop/federation/dfs/data: namenode clusterID = CID-6788a027-b046-4e08-8909-b990e7e331f5; datanode clusterID = CID-78377eff-58d6-470c-97b0-0397405d404c
2021-06-12 07:46:41,683 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020. Exiting.
java.io.IOException: All specified directories are failed to load.
        at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1342)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1308)
        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
        at java.lang.Thread.run(Thread.java:748)
2021-06-12 07:46:41,683 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020
2021-06-12 07:46:41,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-06-12 07:46:43,701 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-06-12 07:46:43,707 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-06-12 07:46:43,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
2021-06-12 08:09:05,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node3/192.168.98.63
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /opt/hadoop-2.6.5/etc/hadoop:/opt/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/opt/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-06-12 08:09:06,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-12 08:09:11,092 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-06-12 08:09:13,838 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-12 08:09:15,312 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-12 08:09:15,312 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-12 08:09:15,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node3
2021-06-12 08:09:15,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-12 08:09:15,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-12 08:09:15,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-12 08:09:15,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-12 08:09:17,081 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-12 08:09:17,149 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-12 08:09:17,288 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-12 08:09:17,315 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-12 08:09:17,315 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-12 08:09:17,315 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-12 08:09:17,495 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-12 08:09:17,514 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-06-12 08:09:17,514 INFO org.mortbay.log: jetty-6.1.26
2021-06-12 08:09:19,824 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@cloud.zte.com.cn:50075
2021-06-12 08:09:22,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-12 08:09:22,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-12 08:09:22,943 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2021-06-12 08:09:23,256 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-12 08:09:23,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-12 08:09:23,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: ns1,ns2
2021-06-12 08:09:23,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: ns1,ns2
2021-06-12 08:09:24,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020 starting to offer service
2021-06-12 08:09:24,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020 starting to offer service
2021-06-12 08:09:24,175 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-12 08:09:24,193 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-12 08:09:26,630 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020. Exiting.
java.io.IOException: Cluster IDs not matched: dn cid=CID-6788a027-b046-4e08-8909-b990e7e331f5 but ns cid=CID-78377eff-58d6-470c-97b0-0397405d404c; bpid=BP-626842139-192.168.98.61-1623454743066
        at org.apache.hadoop.hdfs.server.datanode.DataNode.setClusterId(DataNode.java:604)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1301)
        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
        at java.lang.Thread.run(Thread.java:748)
2021-06-12 08:09:26,805 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.98.61:8020
2021-06-12 08:09:26,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-06-12 08:09:26,986 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/bjsxt/hadoop/federation/dfs/data/in_use.lock acquired by nodename 4280@node3
2021-06-12 08:09:27,048 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /var/bjsxt/hadoop/federation/dfs/data: namenode clusterID = CID-6788a027-b046-4e08-8909-b990e7e331f5; datanode clusterID = CID-78377eff-58d6-470c-97b0-0397405d404c
2021-06-12 08:09:27,049 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020. Exiting.
java.io.IOException: All specified directories are failed to load.
        at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1342)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1308)
        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
        at java.lang.Thread.run(Thread.java:748)
2021-06-12 08:09:27,049 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node2/192.168.98.62:8020
2021-06-12 08:09:27,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-06-12 08:09:29,096 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-06-12 08:09:29,107 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-06-12 08:09:29,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node3/192.168.98.63
************************************************************/
[root@node3 hadoop]# vim core-site.xml
[root@node3 hadoop]#
